{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m5zyWjluC3QV"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from ast import literal_eval\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kD3CiSSe1_Ns"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hatexplain_feature_extractions_v3.csv',\n",
    "                 converters={'word_index_glove': literal_eval, \n",
    "                              'lstm_feature_map': literal_eval,\n",
    "                              'tfidf_word1gram': literal_eval,\n",
    "                              'tfidf_word2gram': literal_eval,\n",
    "                              'tfidf_word3gram': literal_eval,\n",
    "                              'w2v_cbow': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "ryzec0fJIBc2",
    "outputId": "36d983ca-2da6-48d8-fe2f-3ae7aa7b8584"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>vote_ordinal</th>\n",
       "      <th>word_index_glove</th>\n",
       "      <th>lstm_feature_map</th>\n",
       "      <th>tfidf_word1gram</th>\n",
       "      <th>tfidf_word2gram</th>\n",
       "      <th>tfidf_word3gram</th>\n",
       "      <th>w2v_cbow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[46768, 269, 169, 71222, 298, 298, 10625, 3255...</td>\n",
       "      <td>[0.13938053, -0.18590486, -0.060539033, 0.0901...</td>\n",
       "      <td>[4834, 17394, 6750, 1188, 19043, 19043, 11943,...</td>\n",
       "      <td>[36687, 139476, 52026, 9263, 153473, 153092, 9...</td>\n",
       "      <td>[39463, 155726, 56397, 10094, 173291, 172093, ...</td>\n",
       "      <td>[161, 21, 70, 155, 0, 0, 4001, 988, 1, 1, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 580, 11853, 248, 1, 138121, 1476, 15082, 2...</td>\n",
       "      <td>[0.04327799, -0.08438103, -0.060883567, 0.0025...</td>\n",
       "      <td>[3571, 2512, 5937, 14569, 19264, 832, 168, 194...</td>\n",
       "      <td>[27018, 18616, 45642, 119516, 155555, 6181, 15...</td>\n",
       "      <td>[29372, 20476, 48977, 134079, 176031, 6848, 16...</td>\n",
       "      <td>[565, 40, 326, 23, 1, 2026, 1264, 118, 167, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 381085, 42443, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.030954387, 0.040644534, -0.07671745, 0.0194...</td>\n",
       "      <td>[11667, 19441, 11893, 8233, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[94118, 157521, 97062, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[105012, 178166, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 672, 1, 279, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[1594, 1, 120621, 156181, 65387, 1122, 10360, ...</td>\n",
       "      <td>[0.004926282, 0.0012388171, -0.0033861813, 0.0...</td>\n",
       "      <td>[1757, 3491, 3743, 2964, 13434, 97, 17994, 174...</td>\n",
       "      <td>[12858, 26378, 29004, 22211, 108082, 598, 1454...</td>\n",
       "      <td>[13838, 28731, 31520, 24268, 121193, 620, 1623...</td>\n",
       "      <td>[454, 987, 2862, 640, 221, 1793, 81, 1, 569, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[30619, 1, 3623, 12203, 28254, 802, 3214, 5281...</td>\n",
       "      <td>[0.12814277, -0.02799369, -0.022903804, -0.103...</td>\n",
       "      <td>[1758, 19000, 5128, 2393, 2373, 7844, 12652, 7...</td>\n",
       "      <td>[13509, 152337, 38652, 18022, 17904, 62123, 10...</td>\n",
       "      <td>[14667, 169988, 41588, 19867, 19736, 67803, 11...</td>\n",
       "      <td>[10, 1, 313, 3335, 1, 458, 1, 14, 0, 10, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>20143</td>\n",
       "      <td>2</td>\n",
       "      <td>[10360, 1361, 11828, 16, 4027, 780, 21675, 1, ...</td>\n",
       "      <td>[-0.08081896, -0.25950265, 0.078297645, 0.0035...</td>\n",
       "      <td>[17994, 17207, 2640, 14893, 403, 4982, 164, 17...</td>\n",
       "      <td>[145398, 137813, 19819, 121393, 3077, 37458, 1...</td>\n",
       "      <td>[162339, 153834, 21830, 136104, 3273, 40289, 1...</td>\n",
       "      <td>[81, 79, 1, 56, 1763, 457, 1861, 1934, 292, 47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>20144</td>\n",
       "      <td>2</td>\n",
       "      <td>[405, 16, 5281, 10468, 1, 38846, 1, 22696, 528...</td>\n",
       "      <td>[0.020776447, -0.17637987, 0.11507965, 0.00168...</td>\n",
       "      <td>[6997, 14893, 7509, 17862, 3533, 17828, 12902,...</td>\n",
       "      <td>[55464, 121497, 59401, 143889, 26734, 143516, ...</td>\n",
       "      <td>[60568, 136229, 64905, 160529, 29083, 160148, ...</td>\n",
       "      <td>[41, 56, 14, 29, 396, 622, 4, 1699, 14, 1, 622...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>20145</td>\n",
       "      <td>1</td>\n",
       "      <td>[69557, 5027, 7449, 102626, 5027, 20971, 13442...</td>\n",
       "      <td>[0.030287618, -0.091516644, -0.115807004, -0.0...</td>\n",
       "      <td>[10311, 4359, 11291, 18950, 4359, 19629, 6680,...</td>\n",
       "      <td>[83848, 33894, 90844, 151973, 33896, 158813, 5...</td>\n",
       "      <td>[93270, 36609, 101069, 169588, 36611, 179677, ...</td>\n",
       "      <td>[1, 2887, 35, 1, 2887, 3239, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>20146</td>\n",
       "      <td>3</td>\n",
       "      <td>[34849, 662, 85, 1, 967, 35690, 28379, 298, 1,...</td>\n",
       "      <td>[-0.01178721, -0.16269265, -0.07008049, 0.0428...</td>\n",
       "      <td>[1132, 10144, 19311, 4288, 932, 6419, 1629, 19...</td>\n",
       "      <td>[8861, 82483, 156365, 33511, 6904, 48894, 1198...</td>\n",
       "      <td>[9682, 91762, 176956, 36243, 7573, 52363, 1292...</td>\n",
       "      <td>[1715, 25, 63, 1608, 43, 3, 1, 0, 357, 82, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>20147</td>\n",
       "      <td>2</td>\n",
       "      <td>[1316, 157044, 170082, 4689, 93, 1172, 1, 9291...</td>\n",
       "      <td>[-0.066718556, -0.16297267, 0.061089758, 0.124...</td>\n",
       "      <td>[8988, 6864, 5257, 8333, 10967, 11487, 11431, ...</td>\n",
       "      <td>[71104, 53545, 39316, 66229, 88695, 92524, 917...</td>\n",
       "      <td>[78063, 58290, 42250, 72586, 98745, 103139, 10...</td>\n",
       "      <td>[186, 621, 1070, 291, 143, 5, 1858, 3446, 68, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20148 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  vote_ordinal  \\\n",
       "0               0             1   \n",
       "1               1             1   \n",
       "2               2             1   \n",
       "3               3             3   \n",
       "4               4             3   \n",
       "...           ...           ...   \n",
       "20143       20143             2   \n",
       "20144       20144             2   \n",
       "20145       20145             1   \n",
       "20146       20146             3   \n",
       "20147       20147             2   \n",
       "\n",
       "                                        word_index_glove  \\\n",
       "0      [46768, 269, 169, 71222, 298, 298, 10625, 3255...   \n",
       "1      [1, 580, 11853, 248, 1, 138121, 1476, 15082, 2...   \n",
       "2      [1, 381085, 42443, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [1594, 1, 120621, 156181, 65387, 1122, 10360, ...   \n",
       "4      [30619, 1, 3623, 12203, 28254, 802, 3214, 5281...   \n",
       "...                                                  ...   \n",
       "20143  [10360, 1361, 11828, 16, 4027, 780, 21675, 1, ...   \n",
       "20144  [405, 16, 5281, 10468, 1, 38846, 1, 22696, 528...   \n",
       "20145  [69557, 5027, 7449, 102626, 5027, 20971, 13442...   \n",
       "20146  [34849, 662, 85, 1, 967, 35690, 28379, 298, 1,...   \n",
       "20147  [1316, 157044, 170082, 4689, 93, 1172, 1, 9291...   \n",
       "\n",
       "                                        lstm_feature_map  \\\n",
       "0      [0.13938053, -0.18590486, -0.060539033, 0.0901...   \n",
       "1      [0.04327799, -0.08438103, -0.060883567, 0.0025...   \n",
       "2      [0.030954387, 0.040644534, -0.07671745, 0.0194...   \n",
       "3      [0.004926282, 0.0012388171, -0.0033861813, 0.0...   \n",
       "4      [0.12814277, -0.02799369, -0.022903804, -0.103...   \n",
       "...                                                  ...   \n",
       "20143  [-0.08081896, -0.25950265, 0.078297645, 0.0035...   \n",
       "20144  [0.020776447, -0.17637987, 0.11507965, 0.00168...   \n",
       "20145  [0.030287618, -0.091516644, -0.115807004, -0.0...   \n",
       "20146  [-0.01178721, -0.16269265, -0.07008049, 0.0428...   \n",
       "20147  [-0.066718556, -0.16297267, 0.061089758, 0.124...   \n",
       "\n",
       "                                         tfidf_word1gram  \\\n",
       "0      [4834, 17394, 6750, 1188, 19043, 19043, 11943,...   \n",
       "1      [3571, 2512, 5937, 14569, 19264, 832, 168, 194...   \n",
       "2      [11667, 19441, 11893, 8233, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [1757, 3491, 3743, 2964, 13434, 97, 17994, 174...   \n",
       "4      [1758, 19000, 5128, 2393, 2373, 7844, 12652, 7...   \n",
       "...                                                  ...   \n",
       "20143  [17994, 17207, 2640, 14893, 403, 4982, 164, 17...   \n",
       "20144  [6997, 14893, 7509, 17862, 3533, 17828, 12902,...   \n",
       "20145  [10311, 4359, 11291, 18950, 4359, 19629, 6680,...   \n",
       "20146  [1132, 10144, 19311, 4288, 932, 6419, 1629, 19...   \n",
       "20147  [8988, 6864, 5257, 8333, 10967, 11487, 11431, ...   \n",
       "\n",
       "                                         tfidf_word2gram  \\\n",
       "0      [36687, 139476, 52026, 9263, 153473, 153092, 9...   \n",
       "1      [27018, 18616, 45642, 119516, 155555, 6181, 15...   \n",
       "2      [94118, 157521, 97062, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3      [12858, 26378, 29004, 22211, 108082, 598, 1454...   \n",
       "4      [13509, 152337, 38652, 18022, 17904, 62123, 10...   \n",
       "...                                                  ...   \n",
       "20143  [145398, 137813, 19819, 121393, 3077, 37458, 1...   \n",
       "20144  [55464, 121497, 59401, 143889, 26734, 143516, ...   \n",
       "20145  [83848, 33894, 90844, 151973, 33896, 158813, 5...   \n",
       "20146  [8861, 82483, 156365, 33511, 6904, 48894, 1198...   \n",
       "20147  [71104, 53545, 39316, 66229, 88695, 92524, 917...   \n",
       "\n",
       "                                         tfidf_word3gram  \\\n",
       "0      [39463, 155726, 56397, 10094, 173291, 172093, ...   \n",
       "1      [29372, 20476, 48977, 134079, 176031, 6848, 16...   \n",
       "2      [105012, 178166, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3      [13838, 28731, 31520, 24268, 121193, 620, 1623...   \n",
       "4      [14667, 169988, 41588, 19867, 19736, 67803, 11...   \n",
       "...                                                  ...   \n",
       "20143  [162339, 153834, 21830, 136104, 3273, 40289, 1...   \n",
       "20144  [60568, 136229, 64905, 160529, 29083, 160148, ...   \n",
       "20145  [93270, 36609, 101069, 169588, 36611, 179677, ...   \n",
       "20146  [9682, 91762, 176956, 36243, 7573, 52363, 1292...   \n",
       "20147  [78063, 58290, 42250, 72586, 98745, 103139, 10...   \n",
       "\n",
       "                                                w2v_cbow  \n",
       "0      [161, 21, 70, 155, 0, 0, 4001, 988, 1, 1, 1, 1...  \n",
       "1      [565, 40, 326, 23, 1, 2026, 1264, 118, 167, 1,...  \n",
       "2      [1, 672, 1, 279, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "3      [454, 987, 2862, 640, 221, 1793, 81, 1, 569, 5...  \n",
       "4      [10, 1, 313, 3335, 1, 458, 1, 14, 0, 10, 1, 1,...  \n",
       "...                                                  ...  \n",
       "20143  [81, 79, 1, 56, 1763, 457, 1861, 1934, 292, 47...  \n",
       "20144  [41, 56, 14, 29, 396, 622, 4, 1699, 14, 1, 622...  \n",
       "20145  [1, 2887, 35, 1, 2887, 3239, 1, 1, 1, 1, 1, 1,...  \n",
       "20146  [1715, 25, 63, 1608, 43, 3, 1, 0, 357, 82, 1, ...  \n",
       "20147  [186, 621, 1070, 291, 143, 5, 1858, 3446, 68, ...  \n",
       "\n",
       "[20148 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JU_dZVpk2IVU",
    "outputId": "bd16cd07-7a46-4393-90d8-501ca59787b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vote_ordinal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8VJHzBIE9n3M"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>vote_ordinal</th>\n",
       "      <th>word_index_glove</th>\n",
       "      <th>lstm_feature_map</th>\n",
       "      <th>tfidf_word1gram</th>\n",
       "      <th>tfidf_word2gram</th>\n",
       "      <th>tfidf_word3gram</th>\n",
       "      <th>w2v_cbow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[46768, 269, 169, 71222, 298, 298, 10625, 3255...</td>\n",
       "      <td>[0.13938053, -0.18590486, -0.060539033, 0.0901...</td>\n",
       "      <td>[4834, 17394, 6750, 1188, 19043, 19043, 11943,...</td>\n",
       "      <td>[36687, 139476, 52026, 9263, 153473, 153092, 9...</td>\n",
       "      <td>[39463, 155726, 56397, 10094, 173291, 172093, ...</td>\n",
       "      <td>[161, 21, 70, 155, 0, 0, 4001, 988, 1, 1, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 580, 11853, 248, 1, 138121, 1476, 15082, 2...</td>\n",
       "      <td>[0.04327799, -0.08438103, -0.060883567, 0.0025...</td>\n",
       "      <td>[3571, 2512, 5937, 14569, 19264, 832, 168, 194...</td>\n",
       "      <td>[27018, 18616, 45642, 119516, 155555, 6181, 15...</td>\n",
       "      <td>[29372, 20476, 48977, 134079, 176031, 6848, 16...</td>\n",
       "      <td>[565, 40, 326, 23, 1, 2026, 1264, 118, 167, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 381085, 42443, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.030954387, 0.040644534, -0.07671745, 0.0194...</td>\n",
       "      <td>[11667, 19441, 11893, 8233, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[94118, 157521, 97062, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[105012, 178166, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 672, 1, 279, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[1594, 1, 120621, 156181, 65387, 1122, 10360, ...</td>\n",
       "      <td>[0.004926282, 0.0012388171, -0.0033861813, 0.0...</td>\n",
       "      <td>[1757, 3491, 3743, 2964, 13434, 97, 17994, 174...</td>\n",
       "      <td>[12858, 26378, 29004, 22211, 108082, 598, 1454...</td>\n",
       "      <td>[13838, 28731, 31520, 24268, 121193, 620, 1623...</td>\n",
       "      <td>[454, 987, 2862, 640, 221, 1793, 81, 1, 569, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[30619, 1, 3623, 12203, 28254, 802, 3214, 5281...</td>\n",
       "      <td>[0.12814277, -0.02799369, -0.022903804, -0.103...</td>\n",
       "      <td>[1758, 19000, 5128, 2393, 2373, 7844, 12652, 7...</td>\n",
       "      <td>[13509, 152337, 38652, 18022, 17904, 62123, 10...</td>\n",
       "      <td>[14667, 169988, 41588, 19867, 19736, 67803, 11...</td>\n",
       "      <td>[10, 1, 313, 3335, 1, 458, 1, 14, 0, 10, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>20143</td>\n",
       "      <td>2</td>\n",
       "      <td>[10360, 1361, 11828, 16, 4027, 780, 21675, 1, ...</td>\n",
       "      <td>[-0.08081896, -0.25950265, 0.078297645, 0.0035...</td>\n",
       "      <td>[17994, 17207, 2640, 14893, 403, 4982, 164, 17...</td>\n",
       "      <td>[145398, 137813, 19819, 121393, 3077, 37458, 1...</td>\n",
       "      <td>[162339, 153834, 21830, 136104, 3273, 40289, 1...</td>\n",
       "      <td>[81, 79, 1, 56, 1763, 457, 1861, 1934, 292, 47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>20144</td>\n",
       "      <td>2</td>\n",
       "      <td>[405, 16, 5281, 10468, 1, 38846, 1, 22696, 528...</td>\n",
       "      <td>[0.020776447, -0.17637987, 0.11507965, 0.00168...</td>\n",
       "      <td>[6997, 14893, 7509, 17862, 3533, 17828, 12902,...</td>\n",
       "      <td>[55464, 121497, 59401, 143889, 26734, 143516, ...</td>\n",
       "      <td>[60568, 136229, 64905, 160529, 29083, 160148, ...</td>\n",
       "      <td>[41, 56, 14, 29, 396, 622, 4, 1699, 14, 1, 622...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>20145</td>\n",
       "      <td>1</td>\n",
       "      <td>[69557, 5027, 7449, 102626, 5027, 20971, 13442...</td>\n",
       "      <td>[0.030287618, -0.091516644, -0.115807004, -0.0...</td>\n",
       "      <td>[10311, 4359, 11291, 18950, 4359, 19629, 6680,...</td>\n",
       "      <td>[83848, 33894, 90844, 151973, 33896, 158813, 5...</td>\n",
       "      <td>[93270, 36609, 101069, 169588, 36611, 179677, ...</td>\n",
       "      <td>[1, 2887, 35, 1, 2887, 3239, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>20146</td>\n",
       "      <td>3</td>\n",
       "      <td>[34849, 662, 85, 1, 967, 35690, 28379, 298, 1,...</td>\n",
       "      <td>[-0.01178721, -0.16269265, -0.07008049, 0.0428...</td>\n",
       "      <td>[1132, 10144, 19311, 4288, 932, 6419, 1629, 19...</td>\n",
       "      <td>[8861, 82483, 156365, 33511, 6904, 48894, 1198...</td>\n",
       "      <td>[9682, 91762, 176956, 36243, 7573, 52363, 1292...</td>\n",
       "      <td>[1715, 25, 63, 1608, 43, 3, 1, 0, 357, 82, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>20147</td>\n",
       "      <td>2</td>\n",
       "      <td>[1316, 157044, 170082, 4689, 93, 1172, 1, 9291...</td>\n",
       "      <td>[-0.066718556, -0.16297267, 0.061089758, 0.124...</td>\n",
       "      <td>[8988, 6864, 5257, 8333, 10967, 11487, 11431, ...</td>\n",
       "      <td>[71104, 53545, 39316, 66229, 88695, 92524, 917...</td>\n",
       "      <td>[78063, 58290, 42250, 72586, 98745, 103139, 10...</td>\n",
       "      <td>[186, 621, 1070, 291, 143, 5, 1858, 3446, 68, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20148 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  vote_ordinal  \\\n",
       "0               0             1   \n",
       "1               1             1   \n",
       "2               2             1   \n",
       "3               3             3   \n",
       "4               4             3   \n",
       "...           ...           ...   \n",
       "20143       20143             2   \n",
       "20144       20144             2   \n",
       "20145       20145             1   \n",
       "20146       20146             3   \n",
       "20147       20147             2   \n",
       "\n",
       "                                        word_index_glove  \\\n",
       "0      [46768, 269, 169, 71222, 298, 298, 10625, 3255...   \n",
       "1      [1, 580, 11853, 248, 1, 138121, 1476, 15082, 2...   \n",
       "2      [1, 381085, 42443, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [1594, 1, 120621, 156181, 65387, 1122, 10360, ...   \n",
       "4      [30619, 1, 3623, 12203, 28254, 802, 3214, 5281...   \n",
       "...                                                  ...   \n",
       "20143  [10360, 1361, 11828, 16, 4027, 780, 21675, 1, ...   \n",
       "20144  [405, 16, 5281, 10468, 1, 38846, 1, 22696, 528...   \n",
       "20145  [69557, 5027, 7449, 102626, 5027, 20971, 13442...   \n",
       "20146  [34849, 662, 85, 1, 967, 35690, 28379, 298, 1,...   \n",
       "20147  [1316, 157044, 170082, 4689, 93, 1172, 1, 9291...   \n",
       "\n",
       "                                        lstm_feature_map  \\\n",
       "0      [0.13938053, -0.18590486, -0.060539033, 0.0901...   \n",
       "1      [0.04327799, -0.08438103, -0.060883567, 0.0025...   \n",
       "2      [0.030954387, 0.040644534, -0.07671745, 0.0194...   \n",
       "3      [0.004926282, 0.0012388171, -0.0033861813, 0.0...   \n",
       "4      [0.12814277, -0.02799369, -0.022903804, -0.103...   \n",
       "...                                                  ...   \n",
       "20143  [-0.08081896, -0.25950265, 0.078297645, 0.0035...   \n",
       "20144  [0.020776447, -0.17637987, 0.11507965, 0.00168...   \n",
       "20145  [0.030287618, -0.091516644, -0.115807004, -0.0...   \n",
       "20146  [-0.01178721, -0.16269265, -0.07008049, 0.0428...   \n",
       "20147  [-0.066718556, -0.16297267, 0.061089758, 0.124...   \n",
       "\n",
       "                                         tfidf_word1gram  \\\n",
       "0      [4834, 17394, 6750, 1188, 19043, 19043, 11943,...   \n",
       "1      [3571, 2512, 5937, 14569, 19264, 832, 168, 194...   \n",
       "2      [11667, 19441, 11893, 8233, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [1757, 3491, 3743, 2964, 13434, 97, 17994, 174...   \n",
       "4      [1758, 19000, 5128, 2393, 2373, 7844, 12652, 7...   \n",
       "...                                                  ...   \n",
       "20143  [17994, 17207, 2640, 14893, 403, 4982, 164, 17...   \n",
       "20144  [6997, 14893, 7509, 17862, 3533, 17828, 12902,...   \n",
       "20145  [10311, 4359, 11291, 18950, 4359, 19629, 6680,...   \n",
       "20146  [1132, 10144, 19311, 4288, 932, 6419, 1629, 19...   \n",
       "20147  [8988, 6864, 5257, 8333, 10967, 11487, 11431, ...   \n",
       "\n",
       "                                         tfidf_word2gram  \\\n",
       "0      [36687, 139476, 52026, 9263, 153473, 153092, 9...   \n",
       "1      [27018, 18616, 45642, 119516, 155555, 6181, 15...   \n",
       "2      [94118, 157521, 97062, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3      [12858, 26378, 29004, 22211, 108082, 598, 1454...   \n",
       "4      [13509, 152337, 38652, 18022, 17904, 62123, 10...   \n",
       "...                                                  ...   \n",
       "20143  [145398, 137813, 19819, 121393, 3077, 37458, 1...   \n",
       "20144  [55464, 121497, 59401, 143889, 26734, 143516, ...   \n",
       "20145  [83848, 33894, 90844, 151973, 33896, 158813, 5...   \n",
       "20146  [8861, 82483, 156365, 33511, 6904, 48894, 1198...   \n",
       "20147  [71104, 53545, 39316, 66229, 88695, 92524, 917...   \n",
       "\n",
       "                                         tfidf_word3gram  \\\n",
       "0      [39463, 155726, 56397, 10094, 173291, 172093, ...   \n",
       "1      [29372, 20476, 48977, 134079, 176031, 6848, 16...   \n",
       "2      [105012, 178166, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3      [13838, 28731, 31520, 24268, 121193, 620, 1623...   \n",
       "4      [14667, 169988, 41588, 19867, 19736, 67803, 11...   \n",
       "...                                                  ...   \n",
       "20143  [162339, 153834, 21830, 136104, 3273, 40289, 1...   \n",
       "20144  [60568, 136229, 64905, 160529, 29083, 160148, ...   \n",
       "20145  [93270, 36609, 101069, 169588, 36611, 179677, ...   \n",
       "20146  [9682, 91762, 176956, 36243, 7573, 52363, 1292...   \n",
       "20147  [78063, 58290, 42250, 72586, 98745, 103139, 10...   \n",
       "\n",
       "                                                w2v_cbow  \n",
       "0      [161, 21, 70, 155, 0, 0, 4001, 988, 1, 1, 1, 1...  \n",
       "1      [565, 40, 326, 23, 1, 2026, 1264, 118, 167, 1,...  \n",
       "2      [1, 672, 1, 279, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "3      [454, 987, 2862, 640, 221, 1793, 81, 1, 569, 5...  \n",
       "4      [10, 1, 313, 3335, 1, 458, 1, 14, 0, 10, 1, 1,...  \n",
       "...                                                  ...  \n",
       "20143  [81, 79, 1, 56, 1763, 457, 1861, 1934, 292, 47...  \n",
       "20144  [41, 56, 14, 29, 396, 622, 4, 1699, 14, 1, 622...  \n",
       "20145  [1, 2887, 35, 1, 2887, 3239, 1, 1, 1, 1, 1, 1,...  \n",
       "20146  [1715, 25, 63, 1608, 43, 3, 1, 0, 357, 82, 1, ...  \n",
       "20147  [186, 621, 1070, 291, 143, 5, 1858, 3446, 68, ...  \n",
       "\n",
       "[20148 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2CrGgOJ_M-J",
    "outputId": "ce97120a-ecc0-4f79-b761-6964a95716b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vote_ordinal'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ML Models using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lstm_feature_map']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Decision Tree with LSTM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "J2M8cIjRafqu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Best Parameters using Decision Tree DecisionTreeClassifier(max_depth=5, min_samples_leaf=5)\n",
      "Accuracy of Decision Tree with best parameters: 0.434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       286\n",
      "           1       0.42      0.87      0.56      2318\n",
      "           2       0.50      0.10      0.17      1675\n",
      "           3       0.50      0.25      0.34      1766\n",
      "\n",
      "    accuracy                           0.43      6045\n",
      "   macro avg       0.35      0.31      0.27      6045\n",
      "weighted avg       0.45      0.43      0.36      6045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "C1 = DecisionTreeClassifier()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "# grid search\n",
    "grid_search = GridSearchCV(estimator=C1, param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_estimator_\n",
    "dt_best = grid_search.best_estimator_\n",
    "print('Best Parameters using Decision Tree',dt_best)\n",
    "\n",
    "\"\"\"Training with Decision Tree\"\"\"\n",
    "C1 = dt_best\n",
    "C1 = C1.fit(X_train, y_train)\n",
    "y_pred_C1 = C1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Decision Tree with best parameters:\",metrics.accuracy_score(y_test, y_pred_C1).round(3))\n",
    "\n",
    "#y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_C1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 AdaBoost with LSTM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lstm_feature_map']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train = list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       265\n",
      "           1       0.46      0.58      0.51      2326\n",
      "           2       0.38      0.30      0.33      1668\n",
      "           3       0.46      0.45      0.45      1786\n",
      "\n",
      "    accuracy                           0.44      6045\n",
      "   macro avg       0.32      0.33      0.32      6045\n",
      "weighted avg       0.42      0.44      0.42      6045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2), n_estimators=300, learning_rate=1)\n",
    "\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for y_pred in (abc.staged_predict(X_test)):\n",
    "    errors.append(1.0 - accuracy_score(y_pred, y_test))\n",
    "    \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ML Model with tfidf_word1gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tfidf_word1gram']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 tfidf_word1gram with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tfidf_word1gram']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Best Parameters DecisionTreeClassifier(max_depth=5, min_samples_leaf=20)\n",
      "Accuracy of Decision Tree with best parameters: 0.399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       292\n",
      "           1       0.42      0.68      0.52      2379\n",
      "           2       0.30      0.02      0.03      1588\n",
      "           3       0.37      0.43      0.39      1786\n",
      "\n",
      "    accuracy                           0.40      6045\n",
      "   macro avg       0.27      0.28      0.24      6045\n",
      "weighted avg       0.35      0.40      0.33      6045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "C1 = DecisionTreeClassifier()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=C1, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_estimator_\n",
    "dt_best = grid_search.best_estimator_\n",
    "print('Best Parameters',dt_best)\n",
    "\n",
    "\"\"\"Training with Decision Tree\"\"\"\n",
    "C1 = dt_best\n",
    "C1 = C1.fit(X_train, y_train)\n",
    "y_pred_C1 = C1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Decision Tree with best parameters:\",metrics.accuracy_score(y_test, y_pred_C1).round(3))\n",
    "\n",
    "#y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_C1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 tf-idf word1gram with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tfidf_word1gram']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.02      0.03       294\n",
      "           1       0.47      0.65      0.54      2358\n",
      "           2       0.36      0.23      0.28      1588\n",
      "           3       0.51      0.46      0.48      1805\n",
      "\n",
      "    accuracy                           0.45      6045\n",
      "   macro avg       0.35      0.34      0.33      6045\n",
      "weighted avg       0.43      0.45      0.43      6045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2), n_estimators=300, learning_rate=1)\n",
    "\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for y_pred in (abc.staged_predict(X_test)):\n",
    "    errors.append(1.0 - accuracy_score(y_pred, y_test))\n",
    "    \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. w2v_cbow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 w2v_cbow with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['w2v_cbow']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Best Parameters DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=5)\n",
      "Accuracy of Decision Tree with best parameters: 0.409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       284\n",
      "           1       0.41      0.83      0.55      2377\n",
      "           2       0.54      0.05      0.10      1627\n",
      "           3       0.38      0.23      0.29      1757\n",
      "\n",
      "    accuracy                           0.41      6045\n",
      "   macro avg       0.33      0.28      0.23      6045\n",
      "weighted avg       0.42      0.41      0.33      6045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "C1 = DecisionTreeClassifier()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=C1, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_estimator_\n",
    "dt_best = grid_search.best_estimator_\n",
    "print('Best Parameters',dt_best)\n",
    "\n",
    "\"\"\"Training with Decision Tree\"\"\"\n",
    "C1 = dt_best\n",
    "C1 = C1.fit(X_train, y_train)\n",
    "y_pred_C1 = C1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Decision Tree with best parameters:\",metrics.accuracy_score(y_test, y_pred_C1).round(3))\n",
    "\n",
    "#y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_C1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 w2v_cbow with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['w2v_cbow']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.01      0.02       288\n",
      "           1       0.44      0.61      0.51      2314\n",
      "           2       0.39      0.29      0.34      1650\n",
      "           3       0.41      0.34      0.37      1793\n",
      "\n",
      "    accuracy                           0.42      6045\n",
      "   macro avg       0.32      0.31      0.31      6045\n",
      "weighted avg       0.40      0.42      0.40      6045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2), n_estimators=300, learning_rate=1)\n",
    "\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for y_pred in (abc.staged_predict(X_test)):\n",
    "    errors.append(1.0 - accuracy_score(y_pred, y_test))\n",
    "    \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. tfidf_word3gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 tfidf_word3gram with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tfidf_word3gram']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Best Parameters DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=20)\n",
      "Accuracy of Decision Tree with best parameters: 0.39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       280\n",
      "           1       0.40      0.87      0.54      2358\n",
      "           2       0.27      0.02      0.03      1617\n",
      "           3       0.37      0.16      0.22      1790\n",
      "\n",
      "    accuracy                           0.39      6045\n",
      "   macro avg       0.26      0.26      0.20      6045\n",
      "weighted avg       0.33      0.39      0.29      6045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "C1 = DecisionTreeClassifier()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=C1, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_estimator_\n",
    "dt_best = grid_search.best_estimator_\n",
    "\n",
    "print('Best Parameters',dt_best)\n",
    "\n",
    "\"\"\"Training with Decision Tree\"\"\"\n",
    "C1 = dt_best\n",
    "C1 = C1.fit(X_train, y_train)\n",
    "y_pred_C1 = C1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Decision Tree with best parameters:\",metrics.accuracy_score(y_test, y_pred_C1).round(3))\n",
    "\n",
    "#y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_C1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 tfidf_word3gram with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tfidf_word3gram']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.02      0.03       265\n",
      "           1       0.42      0.64      0.51      2315\n",
      "           2       0.33      0.18      0.24      1703\n",
      "           3       0.44      0.38      0.40      1762\n",
      "\n",
      "    accuracy                           0.41      6045\n",
      "   macro avg       0.31      0.30      0.30      6045\n",
      "weighted avg       0.38      0.41      0.38      6045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2), n_estimators=300, learning_rate=1)\n",
    "\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for y_pred in (abc.staged_predict(X_test)):\n",
    "    errors.append(1.0 - accuracy_score(y_pred, y_test))\n",
    "    \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. word_index_glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 word_index_glove with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['word_index_glove']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Best Parameters DecisionTreeClassifier(max_depth=10, min_samples_leaf=20)\n",
      "Accuracy of Decision Tree with best parameters: 0.459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       281\n",
      "           1       0.45      0.74      0.56      2320\n",
      "           2       0.40      0.22      0.28      1655\n",
      "           3       0.54      0.39      0.45      1789\n",
      "\n",
      "    accuracy                           0.46      6045\n",
      "   macro avg       0.35      0.34      0.32      6045\n",
      "weighted avg       0.44      0.46      0.42      6045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "C1 = DecisionTreeClassifier()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=C1, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_estimator_\n",
    "dt_best = grid_search.best_estimator_\n",
    "print('Best Parameters',dt_best)\n",
    "\n",
    "\"\"\"Training with Decision Tree\"\"\"\n",
    "C1 = dt_best\n",
    "C1 = C1.fit(X_train, y_train)\n",
    "y_pred_C1 = C1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Decision Tree with best parameters:\",metrics.accuracy_score(y_test, y_pred_C1).round(3))\n",
    "\n",
    "#y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_C1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 word_index_glove with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['word_index_glove']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.01      0.02       283\n",
      "           1       0.48      0.66      0.56      2300\n",
      "           2       0.40      0.27      0.32      1666\n",
      "           3       0.57      0.54      0.55      1796\n",
      "\n",
      "    accuracy                           0.49      6045\n",
      "   macro avg       0.37      0.37      0.36      6045\n",
      "weighted avg       0.47      0.49      0.47      6045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2), n_estimators=300, learning_rate=1)\n",
    "\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for y_pred in (abc.staged_predict(X_test)):\n",
    "    errors.append(1.0 - accuracy_score(y_pred, y_test))\n",
    "    \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. tfidf_word2gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 tfidf_word3gram with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['word_index_glove']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Best Parameters DecisionTreeClassifier(max_depth=10, min_samples_leaf=50)\n",
      "Accuracy of Decision Tree with best parameters: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       311\n",
      "           1       0.44      0.71      0.55      2314\n",
      "           2       0.37      0.18      0.24      1631\n",
      "           3       0.47      0.40      0.43      1789\n",
      "\n",
      "    accuracy                           0.44      6045\n",
      "   macro avg       0.32      0.32      0.31      6045\n",
      "weighted avg       0.41      0.44      0.40      6045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Daisy Adhikari\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "C1 = DecisionTreeClassifier()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=C1, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_estimator_\n",
    "dt_best = grid_search.best_estimator_\n",
    "print('Best Parameters',dt_best)\n",
    "\n",
    "\"\"\"Training with Decision Tree\"\"\"\n",
    "C1 = dt_best\n",
    "C1 = C1.fit(X_train, y_train)\n",
    "y_pred_C1 = C1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Decision Tree with best parameters:\",metrics.accuracy_score(y_test, y_pred_C1).round(3))\n",
    "\n",
    "#y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_C1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 tfidf_word2gram with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['word_index_glove']\n",
    "y = df.vote_ordinal\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "X_train=list(np.array(X_train))\n",
    "X_test = list(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.01      0.02       266\n",
      "           1       0.51      0.68      0.58      2390\n",
      "           2       0.39      0.30      0.34      1592\n",
      "           3       0.58      0.49      0.53      1797\n",
      "\n",
      "    accuracy                           0.50      6045\n",
      "   macro avg       0.38      0.37      0.37      6045\n",
      "weighted avg       0.48      0.50      0.48      6045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2), n_estimators=300, learning_rate=1)\n",
    "\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for y_pred in (abc.staged_predict(X_test)):\n",
    "    errors.append(1.0 - accuracy_score(y_pred, y_test))\n",
    "    \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
